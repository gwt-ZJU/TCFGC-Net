"""
这部分是卫星图像处理的部分
"""

import numpy as np
import torch
from torch import flatten, nn
from torch.nn import init
from torch.nn.modules.activation import ReLU
from torch.nn.modules.batchnorm import BatchNorm2d
from torch.nn import functional as F
from einops import rearrange
from pool import *
import math
import warnings
from Seg_VIT import *
import numpy as np

def _no_grad_trunc_normal_(tensor, mean, std, a, b):
    # Cut & paste from PyTorch official master until it's in a few official releases - RW
    # Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf
    def norm_cdf(x):
        # Computes standard normal cumulative distribution function
        return (1. + math.erf(x / math.sqrt(2.))) / 2.

    if (mean < a - 2 * std) or (mean > b + 2 * std):
        warnings.warn("mean is more than 2 std from [a, b] in nn.init.trunc_normal_. "
                      "The distribution of values may be incorrect.",
                      stacklevel=2)

    with torch.no_grad():
        # Values are generated by using a truncated uniform distribution and
        # then using the inverse CDF for the normal distribution.
        # Get upper and lower cdf values
        l = norm_cdf((a - mean) / std)
        u = norm_cdf((b - mean) / std)

        # Uniformly fill tensor with values from [l, u], then translate to
        # [2l-1, 2u-1].
        tensor.uniform_(2 * l - 1, 2 * u - 1)

        # Use inverse cdf transform for normal distribution to get truncated
        # standard normal
        tensor.erfinv_()

        # Transform to proper mean, std
        tensor.mul_(std * math.sqrt(2.))
        tensor.add_(mean)

        # Clamp to ensure it's in the proper range
        tensor.clamp_(min=a, max=b)
        return tensor


def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):
    r"""
    Fills the input Tensor with values drawn from a truncated
    normal distribution. The values are effectively drawn from the
    normal distribution :math:`\mathcal{N}(\text{mean}, \text{std}^2)`
    with values outside :math:`[a, b]` redrawn until they are within
    the bounds. The method used for generating the random values works
    best when :math:`a \leq \text{mean} \leq b`.
    Args:
        tensor: an n-dimensional `torch.Tensor`
        mean: the mean of the normal distribution
        std: the standard deviation of the normal distribution
        a: the minimum cutoff value
        b: the maximum cutoff value
    Examples:
        >>> w = torch.empty(3, 5)
        >>> nn.init.trunc_normal_(w)
    """
    return _no_grad_trunc_normal_(tensor, mean, std, a, b)

class LocalExtractUint(nn.Module):
    def __init__(self, indim,dim, act=True):
        super(LocalExtractUint, self).__init__()
        """
        这个是Block的第一部分内容，叫做 局部特征提取单元
        :param dim:维度
        :param act: 是否使用GELU函数和BN
        """
        self.act = act
        self.conv_3x3 = nn.Conv2d(in_channels=indim,out_channels=indim,kernel_size=3,padding=1)
        self.conv_1x1 = nn.Conv2d(in_channels=indim,out_channels=dim,kernel_size=1,padding=0)
        if self.act:
            self.actation = nn.Sequential(
                nn.GELU(),
                nn.BatchNorm2d(dim),
                nn.Dropout(0.5)
            )
        self.RelU = nn.GELU()
        self.apply(self._init_weights)

    def _init_weights(self, m):
        if isinstance(m, nn.Linear):
            trunc_normal_(m.weight, std=.02)
            if isinstance(m, nn.Linear) and m.bias is not None:
                nn.init.constant_(m.bias, 0)
        elif isinstance(m, nn.LayerNorm):
            nn.init.constant_(m.bias, 0)
            nn.init.constant_(m.weight, 1.0)
        elif isinstance(m, nn.Conv2d):
            fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
            fan_out //= m.groups
            m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))
            if m.bias is not None:
                m.bias.data.zero_()

    def forward(self,x):
        if self.act:
            out = self.RelU(self.conv_3x3(x)) + x
            out = self.actation(self.conv_1x1(out))
            return out
        else:
            out = self.RelU(self.conv_3x3(x)) + x
            out = self.conv_1x1(out)
            return out


class Key_Multi_scale(nn.Module):
    """
    对Key的多尺度，先变成三种不同的卷积，最后进行通道的合并
    """
    def __init__(self,dim):
        super(Key_Multi_scale, self).__init__()
        self.dim = dim

        self.conv1x1 = nn.Conv2d(in_channels=self.dim,out_channels=self.dim,kernel_size=1)
        self.conv3x3 = nn.Conv2d(in_channels=self.dim,out_channels=self.dim,kernel_size=3,padding=1)
        self.conv5x5 = nn.Conv2d(in_channels=self.dim, out_channels=self.dim, kernel_size=5, padding=2)
        self.conv_to_dim = nn.Conv2d(in_channels=self.dim*2,out_channels=self.dim,kernel_size=1)
        self.apply(self._init_weights)

    def _init_weights(self, m):
        if isinstance(m, nn.Linear):
            trunc_normal_(m.weight, std=.02)
            if isinstance(m, nn.Linear) and m.bias is not None:
                nn.init.constant_(m.bias, 0)
        elif isinstance(m, nn.LayerNorm):
            nn.init.constant_(m.bias, 0)
            nn.init.constant_(m.weight, 1.0)
        elif isinstance(m, nn.Conv2d):
            fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
            fan_out //= m.groups
            m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))
            if m.bias is not None:
                m.bias.data.zero_()

    def forward(self,x):
        # x_1 = self.conv1x1(x)
        x_3 = self.conv3x3(x)
        x_5 = self.conv5x5(x)
        # out_key = self.conv_to_dim(torch.cat([x_1,x_3,x_5],dim=1))
        out_key = self.conv_to_dim(torch.cat([x_3, x_5], dim=1))
        return out_key

class Attention_embed(nn.Module):
    def __init__(self,dim):
        super(Attention_embed, self).__init__()
        factor = 4 #这个是因子
        self.con1x1 = nn.Conv2d(in_channels=2*dim,out_channels=dim*2//factor,kernel_size=1,bias=False)
        self.bn = nn.BatchNorm2d(dim*2//factor)
        self.relu = nn.GELU()

        """
        接下来是不同尺度的特征矩阵
        """
        self.con1x1_matrix = nn.Conv2d(in_channels=dim*2//factor,out_channels=1*1*dim,kernel_size=1,stride=1)
        self.con3x3_matrix = nn.Conv2d(in_channels=dim * 2 // factor, out_channels=3 * 3 * dim, kernel_size=1, stride=1)
        self.con5x5_matrix = nn.Conv2d(in_channels=dim * 2 // factor, out_channels=5 * 5 * dim, kernel_size=1, stride=1)
        self.apply(self._init_weights)

    def _init_weights(self, m):
        if isinstance(m, nn.Linear):
            trunc_normal_(m.weight, std=.02)
            if isinstance(m, nn.Linear) and m.bias is not None:
                nn.init.constant_(m.bias, 0)
        elif isinstance(m, nn.LayerNorm):
            nn.init.constant_(m.bias, 0)
            nn.init.constant_(m.weight, 1.0)
        elif isinstance(m, nn.Conv2d):
            fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
            fan_out //= m.groups
            m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))
            if m.bias is not None:
                m.bias.data.zero_()

    def forward(self,x):
        bs, c, h, w = x.shape
        c = int(0.5*c)
        """
        先把2*dim变成dim,然后进行平均的注意力矩阵计算
        """
        x = self.relu(self.bn(self.con1x1(x)))

        # att_1 = self.con1x1_matrix(x).reshape(bs,int(c),1*1,h,w).mean(2, keepdim=False).view(bs, c, -1)
        att_3 = self.con3x3_matrix(x).reshape(bs,int(c),3*3,h,w).mean(2, keepdim=False).view(bs, c, -1)
        att_5 = self.con5x5_matrix(x).reshape(bs,int(c),5*5,h,w).mean(2, keepdim=False).view(bs, c, -1)

        # att = (att_5+att_3+att_1)/3
        att = (att_5 + att_3) / 2
        return att

class Feature_Agg_FFN(nn.Module):
    """
    起名叫做:特征聚合前馈网络
    定义：
    1x1的卷积：dim==>out_dim
    """
    def __init__(self,dim,dim_ratio=4):
        super(Feature_Agg_FFN, self).__init__()
        out_dim = dim * dim_ratio
        self.conv1x1_gelu_bn = nn.Sequential(
            nn.Conv2d(in_channels=dim,out_channels=out_dim,kernel_size=1,stride=1),
            nn.GELU(),
            nn.BatchNorm2d(out_dim)
        )

        self.conv1x1 = nn.Conv2d(in_channels=out_dim, out_channels=dim, kernel_size=1, padding=0)
        self.conv3x3 = nn.Conv2d(in_channels=out_dim,out_channels=dim,kernel_size=3,padding=1)
        self.conv5x5 = nn.Conv2d(in_channels=out_dim,out_channels=dim,kernel_size=5,padding=2)

        self.conv1x1_res = nn.Sequential(
            nn.Conv2d(in_channels=dim,out_channels=dim * dim_ratio,kernel_size=1,padding=0),
            nn.BatchNorm2d(dim * dim_ratio)
        )

        self.act = nn.Sequential(
            nn.GELU(),
            nn.BatchNorm2d(dim*3)
        )

        self.conv1x1_bn = nn.Sequential(
            nn.Conv2d(in_channels=dim * 3,out_channels=dim * dim_ratio,kernel_size=1,stride=1),
            nn.BatchNorm2d(dim * dim_ratio)
        )
        self.apply(self._init_weights)

    def _init_weights(self, m):
        if isinstance(m, nn.Linear):
            trunc_normal_(m.weight, std=.02)
            if isinstance(m, nn.Linear) and m.bias is not None:
                nn.init.constant_(m.bias, 0)
        elif isinstance(m, nn.LayerNorm):
            nn.init.constant_(m.bias, 0)
            nn.init.constant_(m.weight, 1.0)
        elif isinstance(m, nn.Conv2d):
            fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
            fan_out //= m.groups
            m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))
            if m.bias is not None:
                m.bias.data.zero_()


    def forward(self,x):
        """
        1.首次经过1x1卷积，修改通道数
        2.不同尺度卷积
        3.cat之后修改通道，并且进行残差
        :param x:
        :return:
        """
        identity = self.conv1x1_res(x)

        out_1 = self.conv1x1_gelu_bn(x)

        out_1x1 = self.conv1x1(out_1)
        out_3x3 = self.conv3x3(out_1)
        out_5x5 = self.conv5x5(out_1)

        cat_feature = torch.cat([out_1x1,out_3x3,out_5x5],dim=1)
        out = self.act(cat_feature)
        out = self.conv1x1_bn(out)
        return out+identity



class GCTNetLayer(nn.Module):
    def __init__(self,dim):
        super(GCTNetLayer, self).__init__()
        """
        self.value_embed:对value进行编码
        self.key_multi_embed:对key进行多尺度上下文信息提取，作为图像的全域表达
        """
        self.dim = dim
        self.value_embed = nn.Sequential(
            nn.Conv2d(in_channels=self.dim, out_channels=self.dim, kernel_size=1),
            nn.BatchNorm2d(self.dim)
        )

        self.key_multi_embed = Key_Multi_scale(dim=self.dim)
        self.att_embed = Attention_embed(dim=self.dim)

    def forward(self,x):
        bs,c,h,w = x.shape
        """
        1.提取全域不同尺度上下文信息获得key
        2.得到value编码
        3.Key与Query在channel维度上进行拼接进行拼接
        4.求不同尺度的注意力矩阵的均值
        5.计算key_2的矩阵，是用sotgmax之后的注意力矩阵*value获取
        6.进行全域特征的二次融合
        """
        #1
        key_1 = self.key_multi_embed(x)
        #2
        value = self.value_embed(x).view(bs, c, -1)
        #3
        y = torch.cat([key_1,x],dim=1)
        #4
        att = self.att_embed(y)
        #5
        key_2 = F.softmax(att,dim=-1) * value
        #6
        key_2 = key_2.view(bs,c,h,w)
        return  key_2+key_1



class CFT_Bottleneck(nn.Module):
    expansion = 4
    def __init__(self,indim,dim,stride=1,downsample=None,use_LEU=True,use_GCT=True,use_FAFN=True,embed_dims=None,num_heads=None,mlp_ratios=None,qkv_bias=None,
                    norm_layer=None,sr_ratios=None,drop_rate=None,drop_path_rate=None):
        super(CFT_Bottleneck, self).__init__()
        self.use_LEU = use_LEU
        self.use_GCT = use_GCT
        self.use_FAFN = use_FAFN

        self.dim = dim
        self.downsample = downsample
        self.stride = stride
        self.LocalExtractUint = LocalExtractUint(indim=indim,dim=self.dim)
        if self.use_LEU:
            self.LocalExtractUint = LocalExtractUint(indim=indim, dim=self.dim)
        if self.use_LEU is not True: #FEU 特征抽取单元
            self.FEU = nn.Sequential(
                nn.Conv2d(in_channels=indim,out_channels=dim,kernel_size=1,padding=0),
                nn.GELU(),
                nn.BatchNorm2d(dim)
            )
        if self.use_GCT:
            self.GCTNetLayer = GCTNetLayer(dim=self.dim)
        if self.use_GCT is not True:
            VIT_Block = Block(dim=embed_dims, num_heads=num_heads, mlp_ratio=mlp_ratios, qkv_bias=qkv_bias,
                    qk_scale=False,
                    drop=drop_rate, attn_drop=0., drop_path=drop_path_rate, norm_layer=norm_layer,
                    sr_ratio=sr_ratios)
            self.Transformer_VIT_Branch = Transformer_VIT_Branch(embed_dim=embed_dims,block=VIT_Block)
        if self.use_FAFN:
            self.Feature_Agg_FFN = Feature_Agg_FFN(dim=self.dim)
        if self.use_FAFN is not True:
            self.FFN = nn.Sequential(
                nn.Conv2d(in_channels=self.dim, out_channels=self.dim*4, kernel_size=1, padding=0),
                nn.GELU()
            )
        self.layer_norm_1 = nn.LayerNorm(self.dim)
        self.layer_norm_2 = nn.LayerNorm(self.dim)




    def forward(self,x):
        """
        0.下采样特征准备
        1.局部特征抽取，在LocalExtractUint里面进行了残差
        2.特征进行翻转，需要进行layernorm
        3.全域上下文提取（需要加上残差）
        4.特征进行翻转，需要进行layernorm
        5.特征聚合前馈网络
        :param x:
        :return:
        """
        """
        排列组合
        1. use_LEU=True   use_GCT=True       use_FAFN=True   SFRAN (FAFN+GCT+VIT)
        2. use_LEU=True   use_GCT=True       use_FAFN=False  GCT+LEU
        3. use_LEU=False  use_GCT=True       use_FAFN=True   GCT+FAFN
        4. use_LEU=True   use_GCT=False(VIT) use_FAFN=True   FAFN+LEU+VIT
        """
        #0
        identity = x
        if self.downsample is not None:
            identity = self.downsample(x)
        #1
        if self.use_LEU:
            local_feature = self.LocalExtractUint(x)
        else:
            local_feature = self.FEU(x)
        #2
        local_feature_norm = local_feature
        #3
        if self.use_GCT:
            Global_feature = self.GCTNetLayer(local_feature_norm)
            Global_feature = Global_feature + local_feature
        else:
            Global_feature = self.Transformer_VIT_Branch(local_feature_norm)
            Global_feature = Global_feature + local_feature
            pass #这个地方写关于VIT的
        #4
        Global_feature_norm = Global_feature
        #5
        if self.use_FAFN:
            Agg_feature = self.Feature_Agg_FFN(Global_feature_norm)
        else:
            Agg_feature = self.FFN(Global_feature_norm)
            # Agg_feature = Global_feature_norm

        return Agg_feature + identity


class PatchAggregation(nn.Module):
    """down sample the feature resolution, build with conv 2x2 stride 2
    """

    def __init__(self, in_channel, out_channel, kernel_size=2, stride_size=2):
        super(PatchAggregation, self).__init__()
        self.patch_aggregation = nn.Conv2d(
            in_channels=in_channel,
            out_channels=out_channel,
            kernel_size=kernel_size,
            stride=stride_size
        )
        # self.patch_aggregation = MixPool2d(kernel_size=2)

    def forward(self, x):
        x = self.patch_aggregation(x)
        return x


class CFTResNet(nn.Module):
    def __init__(self, block, layers, num_classes=1000,use_LEU=True,use_GCT=True,use_FAFN=True,
                 embed_dims=[64, 128, 320], num_heads=[1, 2, 5], mlp_ratios=[4, 4, 4],
                 qkv_bias=True, norm_layer=partial(nn.LayerNorm, eps=1e-6), depths=[2, 2, 2], sr_ratios=[8, 4, 2],
                 drop_rate=0.0, drop_path_rate=0.1
                 ):
        self.inplanes = 32
        super(CFTResNet, self).__init__()
        self.use_LEU = use_LEU
        self.use_GCT = use_GCT
        self.use_FAFN = use_FAFN

        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,
                               bias=False)
        self.bn1 = nn.BatchNorm2d(self.inplanes)
        self.relu = nn.GELU()
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        # self.layer1 = self._make_layer(block, 64, layers[0], stride=1)
        # self.layer2 = self._make_layer(block, 128, layers[1], stride=2)
        # self.layer3 = self._make_layer(block, 256, layers[2], stride=2)
        # self.layer4 = self._make_layer(block, 512, layers[3], stride=2)
        if self.use_GCT:
            self.layer1 = self._make_layer(block, 32, layers[0], stride=1)
            self.layer2 = self._make_layer(block, 64, layers[1], stride=2)
            self.layer3 = self._make_layer(block, 128, layers[2], stride=2)
            self.layer4 = self._make_layer(block, 256, layers[3], stride=2)

        if self.use_GCT is not True:
            self.layer1 = self._make_layer(block, 32, depths[0], stride=1,embed_dims= embed_dims[0],num_heads =num_heads[0],mlp_ratios =mlp_ratios[0],qkv_bias=qkv_bias,
                                           norm_layer=norm_layer,sr_ratios=sr_ratios[0],drop_rate=drop_rate,drop_path_rate=drop_path_rate)
            self.layer2 = self._make_layer(block, 64, depths[1], stride=2,embed_dims= embed_dims[1],num_heads =num_heads[1],mlp_ratios =mlp_ratios[1],qkv_bias=qkv_bias,
                                           norm_layer=norm_layer,sr_ratios=sr_ratios[1],drop_rate=drop_rate,drop_path_rate=drop_path_rate)
            self.layer3 = self._make_layer(block, 128, depths[2], stride=2,embed_dims= embed_dims[2],num_heads =num_heads[2],mlp_ratios =mlp_ratios[2],qkv_bias=qkv_bias,
                                           norm_layer=norm_layer,sr_ratios=sr_ratios[2],drop_rate=drop_rate,drop_path_rate=drop_path_rate)

        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(512 * block.expansion, num_classes)

        self.pool1 = PatchAggregation(in_channel=128,out_channel=128)
        self.pool2 = PatchAggregation(in_channel=256, out_channel=256)
        self.pool3 = PatchAggregation(in_channel=512, out_channel=512)



        # self.pool1 = PatchAggregation(in_channel=256, out_channel=256)
        # self.pool2 = PatchAggregation(in_channel=512, out_channel=512)
        # self.pool3 = PatchAggregation(in_channel=1024, out_channel=1024)

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

    def _make_layer(self, block, planes, blocks, stride=1,embed_dims=None,num_heads=None,mlp_ratios=None,qkv_bias=None,
                    norm_layer=None,sr_ratios=None,drop_rate=None,drop_path_rate=None):
        downsample = None
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = nn.Sequential(
                nn.Conv2d(self.inplanes, planes * block.expansion,
                          kernel_size=1, stride=1, bias=False),
                nn.BatchNorm2d(planes * block.expansion),
            )

        layers = []
        layers.append(block(self.inplanes, planes, stride, downsample,use_LEU=self.use_LEU,use_GCT=self.use_GCT,use_FAFN=self.use_FAFN,embed_dims=embed_dims,num_heads=num_heads,
                            mlp_ratios=mlp_ratios, qkv_bias=qkv_bias,norm_layer=norm_layer,sr_ratios=sr_ratios,drop_rate=drop_rate,drop_path_rate=drop_path_rate))
        self.inplanes = planes * block.expansion
        for i in range(1, blocks):
            layers.append(block(self.inplanes, planes,use_LEU=self.use_LEU,use_GCT=self.use_GCT,use_FAFN=self.use_FAFN,embed_dims=embed_dims,num_heads=num_heads,
                            mlp_ratios=mlp_ratios, qkv_bias=qkv_bias,norm_layer=norm_layer,sr_ratios=sr_ratios,drop_rate=drop_rate,drop_path_rate=drop_path_rate))
        return nn.Sequential(*layers)

    def forward(self, x):
        #stem
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        x = self.layer1(x)
        x = self.pool1(x)

        x = self.layer2(x)
        x = self.pool2(x)

        x = self.layer3(x)
        x = self.pool3(x)

        # x = self.layer4(x)

        # x = self.avgpool(x)
        # x  = torch.flatten(x , 1)
        # x = self.fc(x)

        return x

if __name__ == '__main__':
    """
    用ResNet50的block数量结构
    """
    layers = [3,4,6,3]
    x = torch.rand(16,3,256,256)
    cell = CFTResNet(block=CFT_Bottleneck,layers=layers,num_classes=2,use_FAFN=True,use_GCT=False,use_LEU=True)
    out = cell(x)
